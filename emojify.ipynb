{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojify \n",
    "Here we are going to use word vector representation to build an Emojifier.\n",
    "This can automatically turn this :\n",
    ">\"Congratulations on the promotion! Let's get coffee and talk. Love you!\"\n",
    "\n",
    "To this :\n",
    "\n",
    ">\"Congratulations on the promotion! üëç  Let's get coffee and talk. ‚òïÔ∏è Love you! ‚ù§Ô∏è\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Word Vectors to Improve Emoji Lookups\n",
    "* In many emoji interfaces, we need to remember that ‚ù§Ô∏è  is the \"heart\" symbol rather than the \"love\" symbol. \n",
    "    * In other words, we'll have to remember to type \"heart\" to find the desired emoji, and typing \"love\" won't bring up that symbol.\n",
    "* we can make a more flexible emoji interface by using word vectors!\n",
    "* When using word vectors, we'll see that even if our training set explicitly relates only a few words to a particular emoji, our algorithm will be able to generalize and associate additional words in the test set to the same emoji.\n",
    "    * This works even if those additional words don't even appear in the training set. \n",
    "    * This allows we to build an accurate classifier mapping from sentences to emojis, even using a small training set. \n",
    "\n",
    "### What we'll build:\n",
    "1. In this exercise, we'll start with a baseline model (Emojifier-V1) using word embeddings.\n",
    "2. Then we will build a more sophisticated model (Emojifier-V2) that further incorporates an LSTM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emo_utils import*\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model: Emojifer-V1\n",
    "### Dataset EMOJISET\n",
    "\n",
    "Let's start by building a simple baseline classifier. \n",
    "\n",
    "We have a tiny dataset (X, Y) where:\n",
    "- X contains 127 sentences (strings).\n",
    "- Y contains an integer label between 0 and 4 corresponding to an emoji for each sentence.\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLen = len(max(X_train, key=len).split())\n",
    "maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again :disappointed:\n",
      "I am proud of your achievements :smile:\n",
      "It is the worst day in my life :disappointed:\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n",
      "I love you mum ‚ù§Ô∏è\n",
      "Stop saying bullshit :disappointed:\n",
      "congratulations on your acceptance :smile:\n",
      "The assignment is too long  :disappointed:\n",
      "I want to go play ‚öæ\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    print(X_train[idx], label_to_emoji(Y_train[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the Emojifier-V1\n",
    "<img src='./images/overview_of_v1.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C=5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test,C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 'I missed you' has label index 0, which is emoji ‚ù§Ô∏è\n",
      "Label index 0 in one-hot encoding format is [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "print(f\"Sentence '{X_train[50]}' has label index {Y_train[idx]}, which is emoji {label_to_emoji(Y_train[idx])}\", )\n",
    "print(f\"Label index {Y_train[idx]} in one-hot encoding format is {Y_oh_train[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Emojifier-V1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've loaded:\n",
    "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary \n",
    "    - (400,001 words, with the valid indices ranging from 0 to 400,000)\n",
    "- `index_to_word`: dictionary mapping from indices to their corresponding words in the vocabulary\n",
    "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation. (50-dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is 113317\n",
      "the 113317th word in the vocabulary is cucumber\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "idx = 113317\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "print(\"the\", str(idx) + \"th word in the vocabulary is\", index_to_word[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implements `sentence_to_avg()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    words = sentence.lower().split()\n",
    "    l = 0\n",
    "    avg = np.zeros(word_to_vec_map[any_word].shape)\n",
    "\n",
    "    for w in words:\n",
    "        if w in list(word_to_vec_map.keys()):\n",
    "            avg += word_to_vec_map[w]\n",
    "            l+=1\n",
    "    \n",
    "    if l > 0:\n",
    "        avg = avg/l\n",
    "\n",
    "    return avg\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implements the Model\n",
    "We now have all the pieces to finish implementing the `model()` function! \n",
    "After using `sentence_to_avg()` we need to:\n",
    "* Pass the average through forward propagation\n",
    "* Compute the cost\n",
    "* Backpropagate to update the softmax parameters\n",
    "\n",
    "Implement the `model()` function described in Figure (2). \n",
    "\n",
    "* The equations you need to implement in the forward pass and to compute the cross-entropy cost are below:\n",
    "* The variable $Y_{oh}$ (\"Y one hot\") is the one-hot encoding of the output labels. \n",
    "\n",
    "$$ z^{(i)} = W . avg^{(i)} + b$$\n",
    "\n",
    "$$ a^{(i)} = softmax(z^{(i)})$$\n",
    "\n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Y_{oh,k}^{(i)} * log(a^{(i)}_k)$$\n",
    "\n",
    "**Note** : we will use loops to better understand the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 200):\n",
    "    \"\"\"\n",
    "    Model to train word vector representations in numpy.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
    "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
    "    num_iterations -- number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
    "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
    "    b -- bias of the softmax layer, of shape (n_y,)\n",
    "    \"\"\"\n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    cost = 0\n",
    "    m = Y.shape[0]\n",
    "    n_y = len(np.unique(Y))\n",
    "    n_h = word_to_vec_map[any_word].shape[0]\n",
    "\n",
    "    W = np.random.rand(n_y, n_h) /np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "\n",
    "    Y_oh = convert_to_one_hot(Y,C=n_y)\n",
    "\n",
    "    for t in range(num_iterations):\n",
    "        for i in range(m):\n",
    "            avg = sentence_to_avg(X[i],word_to_vec_map)\n",
    "            \n",
    "            #forward prop\n",
    "            z = np.add(np.dot(W,avg),b)\n",
    "            a = softmax(z)\n",
    "\n",
    "            #cost\n",
    "            cost = -np.sum(np.dot(Y_oh[i],np.log(a)))\n",
    "\n",
    "            #backprop\n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1),avg.reshape(1,n_h))\n",
    "            db = dz \n",
    "\n",
    "            #update\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db \n",
    "\n",
    "            if i % 10 ==0:\n",
    "                print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "                pred = predict(X,Y,W,b,word_to_vec_map)\n",
    "    \n",
    "\n",
    "    return pred, W,b\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n",
      "(132, 5)\n",
      "never talk to me again\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "(20,)\n",
      "(132, 5)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(X_train[0])\n",
    "print(type(X_train))\n",
    "Y = np.asarray([5, 0, 0, 5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
    "print(Y.shape)\n",
    "\n",
    "X = np.asarray(['I am going to the bar tonight', 'I love you', 'miss you my dear',\n",
    " 'Lets go party and have drinks','Congrats on the new job','Congratulations',\n",
    " 'I am so happy for you', 'Why are you feeling bad', 'What is wrong with you',\n",
    " 'You totally deserve this prize', 'Let us go play football',\n",
    " 'Are you down for football this afternoon', 'Work hard play harder',\n",
    " 'It is surprising how people can be dumb sometimes',\n",
    " 'I am very disappointed','It is the best day in my life',\n",
    " 'I think I will end up alone','My life is so boring','Good job',\n",
    " 'Great so awesome'])\n",
    "\n",
    "print(X.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.6325266598703185\n",
      "Accuracy: 0.2196969696969697\n",
      "Epoch: 0 --- cost = 1.31511515631959\n",
      "Accuracy: 0.2803030303030303\n",
      "Epoch: 0 --- cost = 1.1096871792248777\n",
      "Accuracy: 0.2803030303030303\n",
      "Epoch: 0 --- cost = 2.0780418843028015\n",
      "Accuracy: 0.2727272727272727\n",
      "Epoch: 0 --- cost = 0.9942393316543748\n",
      "Accuracy: 0.2727272727272727\n",
      "Epoch: 0 --- cost = 1.9375195920482373\n",
      "Accuracy: 0.25\n",
      "Epoch: 0 --- cost = 1.1814770173191946\n",
      "Accuracy: 0.29545454545454547\n",
      "Epoch: 0 --- cost = 1.772829576659144\n",
      "Accuracy: 0.32575757575757575\n",
      "Epoch: 0 --- cost = 1.238825476537914\n",
      "Accuracy: 0.26515151515151514\n",
      "Epoch: 0 --- cost = 1.5177781474996912\n",
      "Accuracy: 0.4772727272727273\n",
      "Epoch: 0 --- cost = 1.2978760615115696\n",
      "Accuracy: 0.38636363636363635\n",
      "Epoch: 0 --- cost = 1.9136687386211144\n",
      "Accuracy: 0.2878787878787879\n",
      "Epoch: 0 --- cost = 1.9175983452813699\n",
      "Accuracy: 0.5151515151515151\n",
      "Epoch: 0 --- cost = 1.7167260669629125\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 1 --- cost = 1.1886907604751338\n",
      "Accuracy: 0.29545454545454547\n",
      "Epoch: 1 --- cost = 1.0532968659472857\n",
      "Accuracy: 0.2878787878787879\n",
      "Epoch: 1 --- cost = 0.9260595669166265\n",
      "Accuracy: 0.2878787878787879\n",
      "Epoch: 1 --- cost = 1.9360719935076536\n",
      "Accuracy: 0.30303030303030304\n",
      "Epoch: 1 --- cost = 1.0192656538582348\n",
      "Accuracy: 0.29545454545454547\n",
      "Epoch: 1 --- cost = 1.8194348170852628\n",
      "Accuracy: 0.44696969696969696\n",
      "Epoch: 1 --- cost = 1.0633436900381659\n",
      "Accuracy: 0.42424242424242425\n",
      "Epoch: 1 --- cost = 1.5537999268184084\n",
      "Accuracy: 0.5378787878787878\n",
      "Epoch: 1 --- cost = 1.1772290672286445\n",
      "Accuracy: 0.3712121212121212\n",
      "Epoch: 1 --- cost = 1.3273199243770828\n",
      "Accuracy: 0.5757575757575758\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m pred , W, b \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_to_vec_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred)\n",
      "Cell \u001b[0;32mIn[12], line 30\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(X, Y, word_to_vec_map, learning_rate, num_iterations)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n\u001b[0;32m---> 30\u001b[0m         avg \u001b[38;5;241m=\u001b[39m \u001b[43msentence_to_avg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mword_to_vec_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;66;03m#forward prop\u001b[39;00m\n\u001b[1;32m     33\u001b[0m         z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39madd(np\u001b[38;5;241m.\u001b[39mdot(W,avg),b)\n",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m, in \u001b[0;36msentence_to_avg\u001b[0;34m(sentence, word_to_vec_map)\u001b[0m\n\u001b[1;32m     16\u001b[0m avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(word_to_vec_map[any_word]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mword_to_vec_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     20\u001b[0m         avg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m word_to_vec_map[w]\n\u001b[1;32m     21\u001b[0m         l\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "pred , W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.load(\"weights.npy\")\n",
    "b = np.load(\"biases.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Test Set Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "Accuracy: 0.9545454545454546\n",
      "Test Set\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set\")\n",
    "pred_train = predict(X_train, Y_train, W,b, word_to_vec_map)\n",
    "print(\"Test Set\")\n",
    "pred_test = predict(X_test, Y_test, W,b, word_to_vec_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(sentence, W=W, b=b, word_to_vec_map=word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Given X (sentences) and Y (emoji indices), predict emojis and compute the accuracy of your model over the given set.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data containing sentences, numpy array of shape (m, None)\n",
    "    Y -- labels, containing index of the label emoji, numpy array of shape (m, 1)\n",
    "    \n",
    "    Returns:\n",
    "    pred -- numpy array of shape (m, 1) with your predictions\n",
    "    \"\"\"\n",
    "    any_words = list(word_to_vec_map.keys())[0]\n",
    "    n_h = word_to_vec_map[any_words].shape[0]\n",
    "\n",
    "    words = sentence.lower().split()\n",
    "    \n",
    "    avg = np.zeros((n_h,))\n",
    "    count = 0\n",
    "    for w in words:\n",
    "        if w in word_to_vec_map:\n",
    "            avg += word_to_vec_map[w]\n",
    "            count +=1 \n",
    "    \n",
    "    if count > 0:\n",
    "        avg = avg/count\n",
    "\n",
    "    Z = np.dot(W,avg) + b\n",
    "    A = softmax(Z)\n",
    "    pred = np.argmax(A)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚öæ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_emoji(int(predict_single(\"let's play\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let try with the word it has never seen before \\\n",
    "we will try with \"I adore you\" and \"adore\" didnot appear in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you ‚ù§Ô∏è\n",
      "i love you ‚ù§Ô∏è\n",
      "funny lol :smile:\n",
      "lets play with a ball ‚öæ\n",
      "food is ready üç¥\n",
      "not feeling happy :smile:\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Ordering isn't Considered in this Model\n",
    "* Note that the model doesn't get the following sentence correct:\n",
    ">\"not feeling happy\" \n",
    "\n",
    "* This algorithm ignores word ordering, so is not good at understanding phrases like \"not happy\n",
    "\n",
    "### Confusion Matrix\n",
    "* A confusion matrix shows how often an example whose label is one class (\"actual\" class) is mislabeled by the algorithm with a different class (\"predicted\" class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           ‚ù§Ô∏è    ‚öæ    :smile:    :disappointed:   üç¥\n",
      "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
      "Actual                                 \n",
      "0            6    0    0    1    0    7\n",
      "1            0    8    0    0    0    8\n",
      "2            2    0   16    0    0   18\n",
      "3            1    1    2   12    0   16\n",
      "4            0    0    1    0    6    7\n",
      "All          9    9   19   13    6   56\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
